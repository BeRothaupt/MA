\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{Erkl\IeC {\"a}rung}{iii}{chapter*.1}}
\@writefile{toc}{\contentsline {chapter}{Kurzfassung / Abstract}{v}{section*.2}}
\citation{Notter2018}
\citation{Zuern2017}
\citation{Zuern2017}
\citation{Zuern2017}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{ix}{chapter*.4}}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{xi}{chapter*.5}}
\@writefile{toc}{\contentsline {chapter}{Nomenklatur}{xiii}{chapter*.7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Reinforcement Learning}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Markov Decision Process}{3}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}The Agent - Environment System}{3}{section.2.2}}
\citation{Notter2018}
\citation{Notter2018}
\citation{SuttonBarto2018}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.1}{\ignorespaces The Agent-Environment-System \cite  {Notter2018}}}{4}{figure.2.1}}
\newlabel{fig:agent_env_system}{{\relax 2.1}{4}{The Agent-Environment-System \cite {Notter2018}}{figure.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Model Based and Model Free Learning}{4}{section.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Agent}{5}{section.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Return}{5}{section.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Policy}{6}{section.2.6}}
\newlabel{sec:policy}{{2.6}{6}{Policy}{section.2.6}{}}
\newlabel{eq:transprobpi}{{\relax 2.8}{6}{Policy}{equation.2.6.8}{}}
\newlabel{eq:rewardpi}{{\relax 2.9}{6}{Policy}{equation.2.6.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Value Functions}{6}{section.2.7}}
\newlabel{sec:value-function}{{2.7}{6}{Value Functions}{section.2.7}{}}
\newlabel{eq:state_value_fun}{{\relax 2.10}{7}{Value Functions}{equation.2.7.10}{}}
\newlabel{eq:action_value_fun}{{\relax 2.11}{7}{Value Functions}{equation.2.7.11}{}}
\newlabel{eq:state_value_function_with_q}{{\relax 2.12}{7}{Value Functions}{equation.2.7.12}{}}
\newlabel{eq:action_value_function_with_v}{{\relax 2.13}{7}{Value Functions}{equation.2.7.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}The Bellman Expectation Equation}{7}{section.2.8}}
\newlabel{eq:bellman_exp_eq_V_Q}{{\relax 2.14}{7}{The Bellman Expectation Equation}{equation.2.8.14}{}}
\newlabel{eq:bellman_exp_eq_V_determinisic}{{\relax 2.15}{7}{The Bellman Expectation Equation}{equation.2.8.15}{}}
\citation{SuttonBarto2018}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}The Bellman Optimality Equation}{8}{section.2.9}}
\newlabel{eq:bellman_optimality_equation_v_with_q}{{\relax 2.16}{8}{The Bellman Optimality Equation}{equation.2.9.16}{}}
\newlabel{eq:bellman_optimality_equation_stochastic}{{\relax 2.20}{8}{The Bellman Optimality Equation}{equation.2.9.20}{}}
\newlabel{eq:bellman_optimality_equation_deterministic}{{\relax 2.21}{8}{The Bellman Optimality Equation}{equation.2.9.21}{}}
\citation{Zuern2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Dynamic Programming}{9}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter3}{{3}{9}{Dynamic Programming}{chapter.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.1}{\ignorespaces Classification of Machine Learning algorithms}}{9}{figure.3.1}}
\newlabel{fig:model-based-model-free}{{\relax 3.1}{9}{Classification of Machine Learning algorithms}{figure.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.2}{\ignorespaces Figure 3.1 von Markus}}{10}{figure.3.2}}
\newlabel{fig:model-based-model-free}{{\relax 3.2}{10}{Figure 3.1 von Markus}{figure.3.2}{}}
\citation{Bellman1954}
\citation{Bellman1962}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Reward Function}{11}{section.3.1}}
\newlabel{sec:reward}{{3.1}{11}{Reward Function}{section.3.1}{}}
\newlabel{eq:reward_function}{{\relax 3.1}{11}{Reward Function}{equation.3.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The Principle of Optimality}{11}{section.3.2}}
\newlabel{sec:optimality}{{3.2}{11}{The Principle of Optimality}{section.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Types of Dynamic Programming Algorithms}{12}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Policy Evaluation}{12}{subsection.3.3.1}}
\newlabel{subsection:policy_evaluation}{{3.3.1}{12}{Policy Evaluation}{subsection.3.3.1}{}}
\newlabel{eq:bellman_exp}{{\relax 3.3}{12}{Policy Evaluation}{equation.3.3.3}{}}
\newlabel{eq:bellman_exp_discrete_policy}{{\relax 3.4}{12}{Policy Evaluation}{equation.3.3.4}{}}
\newlabel{eq:bellman_exp_update}{{\relax 3.5}{12}{Policy Evaluation}{equation.3.3.5}{}}
\newlabel{eq:bellman_exp_update_bootstrapped}{{\relax 3.7}{12}{Policy Evaluation}{equation.3.3.7}{}}
\newlabel{eq:bellman_exp_update_discrete}{{\relax 3.8}{12}{Policy Evaluation}{equation.3.3.8}{}}
\newlabel{eq:pe_stopping_criterion}{{\relax 3.9}{13}{Policy Evaluation}{equation.3.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Policy Iteration}{13}{subsection.3.3.2}}
\newlabel{sec:PI}{{3.3.2}{13}{Policy Iteration}{subsection.3.3.2}{}}
\newlabel{eq:pi_scheme}{{\relax 3.13}{13}{Policy Iteration}{equation.3.3.13}{}}
\citation{Silver2015}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.3}{\ignorespaces The Policy Iteration Algorithm}}{14}{figure.3.3}}
\newlabel{fig:PI_triangle}{{\relax 3.3}{14}{The Policy Iteration Algorithm}{figure.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Value Iteration}{15}{subsection.3.3.3}}
\newlabel{subsection:VI}{{3.3.3}{15}{Value Iteration}{subsection.3.3.3}{}}
\newlabel{eq:value_iteration_update}{{\relax 3.14}{15}{Value Iteration}{equation.3.3.14}{}}
\newlabel{eq:vi_scheme}{{\relax 3.15}{15}{Value Iteration}{equation.3.3.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}The Contraction Mapping Theorem}{15}{section.3.4}}
\newlabel{sec:contraction_mappings}{{3.4}{15}{The Contraction Mapping Theorem}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Discounted MDPs}{15}{section*.12}}
\newlabel{eq:4.15}{{\relax 3.19}{16}{Discounted MDPs}{equation.3.4.19}{}}
\newlabel{eq:4.16}{{\relax 3.20}{16}{Discounted MDPs}{equation.3.4.20}{}}
\newlabel{eq:4.17}{{\relax 3.21}{16}{Discounted MDPs}{equation.3.4.21}{}}
\newlabel{eq:4.18}{{\relax 3.22}{16}{Discounted MDPs}{equation.3.4.22}{}}
\newlabel{eq:4.19}{{\relax 3.23}{16}{Discounted MDPs}{equation.3.4.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Undiscounted MDPs}{16}{section*.13}}
\newlabel{eq:bellman_undiscounted}{{\relax 3.24}{16}{Undiscounted MDPs}{equation.3.4.24}{}}
\newlabel{eq:n-step-contraction}{{\relax 3.25}{16}{Undiscounted MDPs}{equation.3.4.25}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Function Approximation}{19}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter4}{{4}{19}{Function Approximation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Tables}{19}{section.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Nearest Neighbor}{19}{section*.14}}
\citation{Zuern2017}
\citation{Zuern2017}
\citation{Zuern2017}
\citation{Zuern2017}
\citation{Zuern2017}
\citation{Zuern2017}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Linear Interpolation}{20}{section*.15}}
\newlabel{eq:lin_interpolation}{{\relax 4.1}{20}{Linear Interpolation}{equation.4.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Artificial Neural Networks}{20}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.1}{\ignorespaces A neuron from an artificial neural network \cite  {Zuern2017}}}{21}{figure.4.1}}
\newlabel{fig:neuron}{{\relax 4.1}{21}{A neuron from an artificial neural network \cite {Zuern2017}}{figure.4.1}{}}
\newlabel{eq:theta}{{\relax 4.4}{21}{Artificial Neural Networks}{equation.4.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.2}{\ignorespaces Activation functions \cite  {Zuern2017}}}{22}{figure.4.2}}
\newlabel{fig:activation_functions}{{\relax 4.2}{22}{Activation functions \cite {Zuern2017}}{figure.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.3}{\ignorespaces The MLP used for the policy \cite  {Zuern2017}}}{23}{figure.4.3}}
\newlabel{fig:mlp}{{\relax 4.3}{23}{The MLP used for the policy \cite {Zuern2017}}{figure.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Supervised Learning}{24}{section.4.3}}
\newlabel{lossfun}{{\relax 4.7}{24}{Supervised Learning}{equation.4.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Optimization Techniques}{25}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Gradient Descent}{25}{subsection.4.4.1}}
\newlabel{sec:grad_desc}{{4.4.1}{25}{Gradient Descent}{subsection.4.4.1}{}}
\newlabel{eq:gd_update}{{\relax 4.8}{25}{Gradient Descent}{equation.4.4.8}{}}
\citation{DBLP:journals/corr/KingmaB14}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Stochastic Gradient Descent}{26}{subsection.4.4.2}}
\newlabel{sec:sgd}{{4.4.2}{26}{Stochastic Gradient Descent}{subsection.4.4.2}{}}
\newlabel{sgd_gradient}{{\relax 4.10}{26}{Stochastic Gradient Descent}{equation.4.4.10}{}}
\newlabel{sgd_update}{{\relax 4.11}{26}{Stochastic Gradient Descent}{equation.4.4.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}The ADAM Algorithm}{26}{subsection.4.4.3}}
\newlabel{sec:adam}{{4.4.3}{26}{The ADAM Algorithm}{subsection.4.4.3}{}}
\newlabel{eq:adam_update}{{\relax 4.12}{26}{The ADAM Algorithm}{equation.4.4.12}{}}
\newlabel{eq:adam_hat_m}{{\relax 4.13}{26}{The ADAM Algorithm}{equation.4.4.13}{}}
\newlabel{eq:adam_hat_v}{{\relax 4.14}{26}{The ADAM Algorithm}{equation.4.4.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Overfitting}{27}{section.4.5}}
\citation{Fichter2009}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Trajectory Optimization with Policy Iteration}{29}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Glider Representation}{29}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}2D Environment}{29}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Policy Representation}{29}{subsection.5.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Equations of Motion}{29}{subsection.5.2.2}}
\citation{Fichter2009}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 5.1}{\ignorespaces Angles in three-dimensional flight.}}{30}{figure.5.1}}
\newlabel{fig:coords2d}{{\relax 5.1}{30}{Angles in three-dimensional flight}{figure.5.1}{}}
\newlabel{eq:dotgamma}{{\relax 5.4}{31}{Equations of Motion}{equation.5.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Maximum Range in a given Configuration}{31}{subsection.5.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Following the Line of Sight Towards the Target}{31}{subsection.5.2.4}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax 5.1}{\ignorespaces Grid parameters for trajectory optimization}}{32}{table.5.1}}
\newlabel{tab:grids}{{\relax 5.1}{32}{Grid parameters for trajectory optimization}{table.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Discretization of the State- and Action Space}{32}{subsection.5.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}3D Environment}{32}{section.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 5.2}{\ignorespaces The discretized state space. For $x_3$ and $z_4$, the grid for the speed vector is drawn.}}{33}{figure.5.2}}
\newlabel{fig:2d_state_space_discretized}{{\relax 5.2}{33}{The discretized state space. For $x_3$ and $z_4$, the grid for the speed vector is drawn}{figure.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Discretization of the state and action space}{33}{subsection.5.3.1}}
\def \dpthimport {\newlabel {tikz:opiOPI500m}{{6.1}{\thepage }{2D Policy Iteration}{section.6.1}{}}}\dpthimport 
\def \dpthimport {\newlabel {tikz:gpi500m}{{6.1}{\thepage }{2D Policy Iteration}{figure.6.2}{}}}\dpthimport 
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Results}{35}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter6}{{6}{35}{Results}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}2D Policy Iteration}{35}{section.6.1}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax 6.1}{\ignorespaces Comparison of flight- and computation-time for OC, PI and VI}}{35}{table.6.1}}
\newlabel{tab:2d_flighttimes}{{\relax 6.1}{35}{Comparison of flight- and computation-time for OC, PI and VI}{table.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.1}{\ignorespaces Results of Optimistic Policy Iteration (blue) and Optimal Control (red) (die nochmal wiederholen... anderes konvergenzkriterium?)}}{36}{figure.6.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}3D Scenarios}{36}{section.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.2}{\ignorespaces Trajectory and angle of attack after 100 Value Iterations}}{37}{figure.6.2}}
\newlabel{fig:2d_trajectory_VI}{{\relax 6.2}{37}{Trajectory and angle of attack after 100 Value Iterations}{figure.6.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax 6.2}{\ignorespaces Comparison of flight- and computation-time for OC, PI and VI}}{37}{table.6.2}}
\newlabel{tab:2d_flighttimes}{{\relax 6.2}{37}{Comparison of flight- and computation-time for OC, PI and VI}{table.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.3}{\ignorespaces Results of Generalized Policy Iteration (blue) and Optimal Control (red)}}{38}{figure.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 6.4}{\ignorespaces Trajectory and angle of attack after 100 iterations of Generalized Policy Iteration with 100 evaluation steps in each iteration}}{39}{figure.6.4}}
\newlabel{fig:2d_flighttimes_GPI_OPI}{{\relax 6.4}{39}{Trajectory and angle of attack after 100 iterations of Generalized Policy Iteration with 100 evaluation steps in each iteration}{figure.6.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Discussion}{41}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix A: Glider Parameters and Scenario Data}{43}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix_A}{{A}{43}{Appendix A: Glider Parameters and Scenario Data}{appendix.A}{}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax A.1}{\ignorespaces glider data}}{43}{table.A.1}}
\newlabel{tab:glider_data}{{\relax A.1}{43}{glider data}{table.A.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax A.2}{\ignorespaces scenario data}}{43}{table.A.2}}
\newlabel{tab:glider_data}{{\relax A.2}{43}{scenario data}{table.A.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Appendix B: Computer Configuration}{45}{appendix.B}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix_B}{{B}{45}{Appendix B: Computer Configuration}{appendix.B}{}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax B.1}{\ignorespaces computer specifications}}{45}{table.B.1}}
\newlabel{tab:pc_specs}{{\relax B.1}{45}{computer specifications}{table.B.1}{}}
\bibstyle{abbrvdin}
\bibdata{./src/bib/bibfile}
\bibcite{Bellman1954}{1}
\bibcite{Bellman1962}{2}
\bibcite{Fichter2009}{3}
\bibcite{DBLP:journals/corr/KingmaB14}{4}
\bibcite{Notter2018}{5}
\bibcite{Silver2015}{6}
\bibcite{SuttonBarto2018}{7}
\bibcite{Zuern2017}{8}
\@writefile{toc}{\contentsline {chapter}{Literaturverzeichnis}{47}{table.B.1}}
\global\@altsecnumformattrue
