\babel@toc {english}{}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {\relax 2.1}{\ignorespaces The Agent-Environment-System \cite {Notter2018}}}{4}{figure.2.1}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {\relax 3.1}{\ignorespaces Classification of Machine Learning algorithms}}{11}{figure.3.1}
\contentsline {figure}{\numberline {\relax 3.2}{\ignorespaces Figure 3.1 von Markus}}{12}{figure.3.2}
\contentsline {figure}{\numberline {\relax 3.3}{\ignorespaces The Policy Iteration Algorithm}}{16}{figure.3.3}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {\relax 4.1}{\ignorespaces A neuron from an artificial neural network \cite {Zuern2017}}}{23}{figure.4.1}
\contentsline {figure}{\numberline {\relax 4.2}{\ignorespaces Activation functions \cite {Zuern2017}}}{24}{figure.4.2}
\contentsline {figure}{\numberline {\relax 4.3}{\ignorespaces The MLP used for the policy \cite {Zuern2017}}}{25}{figure.4.3}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {\relax 5.1}{\ignorespaces Angles in three-dimensional flight.}}{32}{figure.5.1}
\contentsline {figure}{\numberline {\relax 5.2}{\ignorespaces The discretized state space. For $x_3$ and $z_4$, the grid for the speed vector is drawn.}}{33}{figure.5.2}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {\relax 6.1}{\ignorespaces Trajectory and angle of attack after 100 Value Iterations}}{37}{figure.6.1}
\contentsline {figure}{\numberline {\relax 6.2}{\ignorespaces Trajectory and angle of attack after 100 iterations of Generalized Policy Iteration with 100 evaluation steps in each iteration}}{38}{figure.6.2}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
