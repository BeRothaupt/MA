\begin{thenomenclature} 

 \nomgroup{A}

  \item [{ANN}]\begingroup Artificial Neural Network\nomeqref {\relax 4.2}
		\nompageref{19}
  \item [{CPU}]\begingroup central processing unit\nomeqref {\relax B.0}
		\nompageref{41}
  \item [{DP}]\begingroup Dynamic Programming\nomeqref {\relax 1.0}
		\nompageref{2}
  \item [{GPI}]\begingroup Generalized Policy Iteration\nomeqref {\relax 0}
		\nompageref{xiii}
  \item [{GPU}]\begingroup graphics processing unit\nomeqref {\relax B.0}
		\nompageref{41}
  \item [{iFR}]\begingroup Institute for Flight Mechanics and Control\nomeqref {\relax 0}
		\nompageref{xiii}
  \item [{MDP}]\begingroup Markov Decision Process\nomeqref {\relax 1.0}
		\nompageref{2}
  \item [{MLP}]\begingroup multi layer perceptron\nomeqref {\relax 4.2}
		\nompageref{18}
  \item [{MSE}]\begingroup mean squared error\nomeqref {\relax 4.6}
		\nompageref{22}
  \item [{OPI}]\begingroup Optimistic Policy Iteration\nomeqref {\relax 0}
		\nompageref{xiii}
  \item [{PE}]\begingroup Policy Evaluation\nomeqref {\relax 0}
		\nompageref{xiii}
  \item [{PI}]\begingroup Policy Iteration\nomeqref {\relax 0}
		\nompageref{xiii}
  \item [{RAM}]\begingroup random access memory\nomeqref {\relax B.0}
		\nompageref{41}
  \item [{RL}]\begingroup Reinforcement Learning\nomeqref {\relax 0}
		\nompageref{xiii}
  \item [{SL}]\begingroup Supervised Learning\nomeqref {\relax 0}
		\nompageref{xiii}
  \item [{VI}]\begingroup Value Iteration\nomeqref {\relax 0}
		\nompageref{xiii}
  \item [{VRAM}]\begingroup video random access memory\nomeqref {\relax 0}
		\nompageref{xiii}

 \nomgroup{G}

  \item [{$\alpha$}]\begingroup \nomenunit{\unit{rad}} angle of attack\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\boldsymbol{\theta}$}]\begingroup parameter vector\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\gamma$}]\begingroup discount factor\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\Lambda$}]\begingroup aspect ratio\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\mu$}]\begingroup mean\nomeqref {\relax 0}\nompageref{xiv}
  \item [{$\phi$}]\begingroup \nomenunit{\unit{rad}} flight path angle\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\pi$}]\begingroup policy\nomeqref {\relax 0}\nompageref{xiv}
  \item [{$\sigma$}]\begingroup standard deviation\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$e$}]\begingroup oswald efficiency factor\nomeqref {\relax 0}
		\nompageref{xiv}

 \nomgroup{L}

  \item [{$\boldsymbol{b}$}]\begingroup bias\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\boldsymbol{W}$}]\begingroup weights\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\Delta t$}]\begingroup time step\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\mathcal{A}$}]\begingroup action space\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\mathcal{N}$}]\begingroup Gaussian Distribution\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\mathcal{P}$}]\begingroup State Transition Probability\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\mathcal{S}$}]\begingroup state space\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$\rho$}]\begingroup \nomenunit{\unit{\frac{kg}{m^3}}}air density\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$a$}]\begingroup action\nomeqref {\relax 0}\nompageref{xiv}
  \item [{$m$}]\begingroup \nomenunit{\unit{kg}}glider mass\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$o$}]\begingroup observation\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$Q$}]\begingroup Action Value Function\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$q$}]\begingroup \nomenunit{\unit{\frac{N}{m^2}}}dynamic pressure\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$r$}]\begingroup reward\nomeqref {\relax 0}\nompageref{xiv}
  \item [{$s$}]\begingroup state\nomeqref {\relax 0}\nompageref{xiv}
  \item [{$V$}]\begingroup State Value Function\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{D}]\begingroup drag\nomeqref {\relax 0}\nompageref{xiv}
  \item [{L}]\begingroup lift\nomeqref {\relax 0}\nompageref{xiv}

 \nomgroup{S}

  \item [{$*$}]\begingroup optimal\nomeqref {\relax 0}\nompageref{xiv}
  \item [{$\pi$}]\begingroup w.r.t. policy $\pi$\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{$T$}]\begingroup terminal\nomeqref {\relax 0}\nompageref{xiv}
  \item [{$t$}]\begingroup time step\nomeqref {\relax 0}
		\nompageref{xiv}
  \item [{D}]\begingroup drag\nomeqref {\relax 0}\nompageref{xiv}
  \item [{L}]\begingroup lift\nomeqref {\relax 0}\nompageref{xiv}

\end{thenomenclature}
