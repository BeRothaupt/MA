% !TeX root = ../../../Main.tex

\chapter{Appendix A: Glider Parameters and Scenario Data}
\label{appendix_A}

\begin{table}[h]
	\begin{center}
		\begin{tabular}{r|l}
			mass m& $3.366 kg$\\
			wing area S & $0.568 m^2$ \\
			aspect ratio $\Lambda$ & $10.2$ \\
			oswald efficiency factor e& $0.9$ \\
			$c_{D0}$ & 0.015 \\
		\end{tabular}
		\caption{glider data}
		\label{tab:glider_data}
	\end{center}
\end{table}
Table \ref{tab:scenario_data} contains the start states and normalization values (cf. \ref{sec:input_standardization}) for each scenario. For each scenario, there is a separate mean $\mu$ and standard deviation $\sigma$ for each coordinate. Therefore, each column contains a vector of means and standard deviations.
\begin{table}[h]
	\begin{center}
		\begin{tabular}{r|c c c}
			scenario & 1 & 2 & 3 \\ \hline
			distance $d_T$ & 500m & 1000m & 2000m\\
			start state $s_0$ & $s_0 = [0, 100, 0, 0]^\top$ &  $s_0 = [0, 100, 0, 0]^\top$  &  $s_0 = [0, 100, 0, 0]^\top$  \\
			normalization $\mu$ &  & $[500, 50, 10, 5]$ & $[1000, 50, 15, 1]$ \\
			normalization $\sigma$ & & $[300, 30, 5, 2]$ & $[600, 30, 6, 3]$
			\end{tabular}
		\caption{scenario data}
		\label{tab:scenario_data}
	\end{center}
\end{table}

\chapter{Appendix B: Computer Configuration}
\label{appendix_B}
Table \ref{tab:pc_specs} contains the technical data of the system used for calculations. All calculations were performed in phyton. The policy ANN used in the simulations was handled by the GPU\nomenclature[A]{GPU}{graphics processing unit} using CUDNN, Theano and Lasagne. All other code including the tables representing the greedy actions and state values was executed with eight parallel processes on the CPU\nomenclature[A]{CPU}{central processing unit}.

\begin{table}[h]
	\begin{center}
		\begin{tabular}{r|l}
			CPU & Intel i7-7700HQ @ 2.80 GHz (4 physical cores, 8 threads) \\
			RAM\nomenclature[A]{RAM}{random access memory} & 16 GB DDR3 RAM @ 3200 MHz \\
			GPU & Nvidia Geforce GTX 1050 Ti (4 GB VRAM, 768 CUDA cores) \\
			OS & Ubuntu 16.04 LTS
		\end{tabular}
	\caption{computer specifications}
	\label{tab:pc_specs}
	\end{center}
\end{table}

\chapter{Appendix C: Table Representation of the Value Function and Policy}
\label{appendix_C}

\chapter{Appendix D: Optimistic Policy Iteration}
\label{appendix_D}

\begin{algorithm}
	\caption{Optimistic Policy Iteration}
	\begin{algorithmic}[0] % 1 to show code line numbers
		\Function{Optimistic Policy Iteration}{}
		\State
		\State Initialize $V(s) = 0 \; \forall \; s \in \mathcal{S}$
		\State Load arbitrary initial policy $\pi_0$.
		\State Initialize $m$,\;$\epsilon_V$
		\While {true}			
		\State
		\Function{Policy Evaluation}{}
		\ForAll{$s \in \mathcal{S}$}
		\State $V_{\pi,new}(s) \mathrel{\reflectbox{\ensuremath{\mapsto}}} r+\gamma V_ {\pi,old}(s')$
		\EndFor
		\EndFunction
		\State
		\Function{Policy Improvement}{}
		\ForAll{$s \in \mathcal{S}$}
		\State sample $m$ actions $a_n(s)$
		\ForAll {$a_n$}
		\State $Q(s,a_n) = r + \gamma V(s')$
		\EndFor
		\State $a_{greedy}(s)=\underset{a_n}{\text{argmax}}[Q(s,a_n)]$
		\EndFor
		\EndFunction
			\State Train policy on $a_{greedy,new}$ to obtain $\pi_{new}$
		\State
		\If {$||a_{greedy,new}-a_{greedy,old}||_\infty = 0$}
		\State break
		\EndIf	
		\EndWhile
		\State
		\EndFunction
	\end{algorithmic}
	\label{algo:opi}
\end{algorithm}

